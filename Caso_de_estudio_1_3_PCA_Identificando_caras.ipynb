{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paucaroscanoa/ApiBookAuthor/blob/master/Caso_de_estudio_1_3_PCA_Identificando_caras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUS4NJXvsI8M"
      },
      "source": [
        "# Caso de estudio 1.3: *PCA* - Identificando caras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqTSDvHQsI8N"
      },
      "source": [
        "---\n",
        "<br>\n",
        "\n",
        "**Recursos adicionales:**\n",
        "\n",
        "* Guía del caso de estudio\n",
        "* Artículo original de Matthew A. Turk y Alex P. Pentland: [Face Recognition Using Eigenfaces](http://www.mit.edu/~9.54/fall14/Classes/class10/Turk%20Pentland%20Eigenfaces.pdf)\n",
        "* Caso de estudio de JHU: [Eigenfaces for Face Detection/Recognition](http://www.vision.jhu.edu/teaching/vision08/Handouts/case_study_pca1.pdf)\n",
        "* Entradas de blogs:\n",
        "    * [EigenFaces and A Simple Face Detector with PCA/SVD in Python](https://sandipanweb.wordpress.com/2018/01/06/eigenfaces-and-a-simple-face-detector-with-pca-svd-in-python/)\n",
        "    * [How to Get Eigenfaces](https://medium.com/@lwj.liuwenjing/how-to-get-eigenfaces-a9caeeba8767) ([source code](https://colab.research.google.com/drive/1T3cSvQZjKhh8s3Dxrb9gPCWhwhcz4Bmo#scrollTo=q2mPsa4M3Jkc)\n",
        "    * [Eigenfaces: Recovering Humans from Ghosts](https://towardsdatascience.com/eigenfaces-recovering-humans-from-ghosts-17606c328184)\n",
        "    \n",
        "<br>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrp4DeJfsI8O"
      },
      "source": [
        "Configuración del notebook:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGKEP3JNJD3C"
      },
      "source": [
        "Sincronice su cuenta de Google. Para ello, siga el link que aparece en la salida de la siguiente celda una vez ejecutada. Copie el código que le aparece en pantalla e introdúzcalo en la salida de la celda.\n",
        "\n",
        "Esta celda también le permitirá importar la base de datos que se usará en este caso de estudio.\n",
        "\n",
        "Una vez vea el mensaje: `¡Google Drive sincronizado y base de datos importada con éxito!` puede continuar ejecutando el resto de celdas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Avqk5K7KJBXT"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import zipfile\n",
        "\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "data_drop = drive.CreateFile({'id':'1Ef3kc82CVbUAqudU1gKs0rxxKC25jdaq'})\n",
        "data_drop.GetContentFile('training_set.zip')\n",
        "with zipfile.ZipFile('training_set.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "data_drop = drive.CreateFile({'id':'1OfGSJGEzQENEUDL-yGem0fb_zV1og2Lo'})\n",
        "data_drop.GetContentFile('test_set.zip')\n",
        "with zipfile.ZipFile('test_set.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "print('¡Google Drive sincronizado y base de datos importada con éxito!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAIoizC1EZGu"
      },
      "source": [
        "# Nueva sección"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5u85dV-EZzp"
      },
      "source": [
        "# Nueva sección"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKgusi9QtrA3"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9sLdKV4JDB-"
      },
      "source": [
        "Importar librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unh5CQgfsI8O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "import os\n",
        "\n",
        "#Visualización\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage\n",
        "from skimage import io, color, transform, exposure\n",
        "\n",
        "\n",
        "print('\\n¡Librerías importadas con éxito!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi2sgzEQsI8S"
      },
      "source": [
        "# Base de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFTHv9WKsI8T"
      },
      "source": [
        "---\n",
        "<br>\n",
        "\n",
        "En este ejemplo se utiliza la base de datos pública [LFWcrop](http://conradsanderson.id.au/lfwcrop/), desarrollada por Conrad Sanderson. Esta base de datos es un subconjunto de una base de datos mayor llamada [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/) (LFW), y que se utiliza mucho en _Computer vision_.\n",
        "\n",
        "Esta base de datos está compuesta de imágenes de 64x64 píxeles, que contienen caras de personas. Las imágenes se han cortado de modo que la cara ocupe toda la imagen. La versión en escala de grises de todas las imágenes puede encontrarse en [`Data/lfwcrop_grey_faces`](https://drive.google.com/drive/folders/1sdDB6utZeRGOgfF7PZhk6wTj3Qhjv1Fm?usp=sharing). La base de datos cuenta con 13233 imágenes, pero en este ejemplo usaremos 100.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu8-IOansI8T"
      },
      "source": [
        "La base de datos contiene más de una imagen para ciertas personas. El conjunto de entrenamiento estará compuesto de 100 (M) imágenes de personas __diferentes__. Pueden explorarse otros tamaños del conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAx2MXHHQWfy"
      },
      "outputs": [],
      "source": [
        "#Número de imágenes en el conjunto de entrenamiento (max 100)\n",
        "M = 100\n",
        "print('Tamaño del conjunto de entrenamiento: {} imágenes'.format(M))\n",
        "\n",
        "#Definir tamaño de las imágenes\n",
        "irow,icol = (64,64)\n",
        "\n",
        "\n",
        "#Importar los nombres de las M primeras imágenes del conjunto de entrenamiento\n",
        "dir_='training_set/'\n",
        "training_set_filenames = os.listdir(dir_)\n",
        "training_set_filenames.remove('.DS_Store')\n",
        "print(training_set_filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51uaE-RVsI8Z"
      },
      "source": [
        "Podemos importar las imágenes, \"aplanarlas\" (transformar una matriz de $N_1xN_2$ píxeles en un vector de $N_1xN_2$ valores de longitud), y almacenarlas en un matriz (`S_raw`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf6DnWOesI8Z"
      },
      "outputs": [],
      "source": [
        "S_raw = np.ndarray((irow*icol,M))\n",
        "\n",
        "for i in range(M):\n",
        "    #carga img\n",
        "    img = io.imread('training_set/{}'.format(training_set_filenames[i]))\n",
        "    #img = color.rgb2gray(img)\n",
        "    img = transform.resize(img, (irow,icol),anti_aliasing=True)\n",
        "    #Añade img a la matriz\n",
        "    S_raw[:,i]= img.flatten()\n",
        "\n",
        "print('Dimensões de S_raw: {}'.format(S_raw.shape))\n",
        "print('S_raw dtype: {}'.format(S_raw.dtype))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73H0_SNE1PcV"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTdepeXwsI8c"
      },
      "source": [
        "## Funciones auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKkMKxzTsI8c"
      },
      "source": [
        "Algunas funciones auxiliares para visualizar las imágenes durante el caso de estudio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NGnZJvisI8c"
      },
      "outputs": [],
      "source": [
        "def plot_images(S,title=''):\n",
        "    S = S[:,:16].copy()\n",
        "    fig, axes = plt.subplots(nrows=round(S.shape[1]/8), ncols=8,figsize=(12,4))\n",
        "    plt.subplots_adjust(wspace = 0.2,hspace = 0.2)\n",
        "    ax = axes.ravel()\n",
        "    fig.suptitle(title, fontsize = 16, y=0.95)\n",
        "    for i in range(S.shape[1]):\n",
        "        #Mostrar las img\n",
        "        ax[i].imshow(S[:,i].reshape((irow,icol)), cmap='gray')\n",
        "        ax[i].get_xaxis().set_visible(False)\n",
        "        ax[i].get_yaxis().set_visible(False)\n",
        "    plt.show()\n",
        "\n",
        "plot_images(S_raw,title='Imágenes en bruto (RAW)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxW55TECsI8i"
      },
      "source": [
        "# Preprocesamiento de imágenes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jfIoI3CsI8i"
      },
      "source": [
        "Para poder acondicionar el conjunto de entrenamiento conviene normalizar (hacer que todas las imágenes tengan la misma media y desviación estándar) y centrar cada imagen (restar la imagen media de todo el conjunto a cada imagen)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hAwz_9isI8j"
      },
      "outputs": [],
      "source": [
        "S_processed = S_raw.copy()\n",
        "plot_images(S_raw,title='Imágenes en bruto (RAW)')\n",
        "#Normalización\n",
        "um = S_processed.mean(axis=1)\n",
        "ustd = S_processed.std(axis=1)\n",
        "for i in range(M):\n",
        "    S_processed[:,i] = (S_processed[:,i] - S_processed[:,i].mean()) * ustd/S_processed[:,i].std() + um\n",
        "\n",
        "plot_images(S_processed,title='Imágenes normalizadas')\n",
        "\n",
        "#Centrado\n",
        "mean_img = S_processed.mean(axis= 1)\n",
        "for i in range(M):\n",
        "    S_processed[:,i] = S_processed[:,i] - mean_img\n",
        "\n",
        "plot_images(S_processed,title = 'Imágenes normalizadas y centradas')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2L8OvgFsI8m"
      },
      "source": [
        "También podemos visualizar la \"imagen media\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilNjufrTsI8n"
      },
      "outputs": [],
      "source": [
        "ax,fig = plt.subplots()\n",
        "plt.imshow(skimage.img_as_ubyte(mean_img.reshape((irow,icol))), cmap='gray')\n",
        "plt.title('Imagen promedio',fontsize= 16)\n",
        "fig.axes.get_xaxis().set_visible(False)\n",
        "fig.axes.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOCyNsXbsI8q"
      },
      "source": [
        "# Calculando las  \"eigencaras\" o \"caras propias\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6gPLMO3sI8q"
      },
      "source": [
        "Las _eigencaras_ son los vectores propios de la matriz de covarianza del conjunto de entrenamiento.\n",
        "\n",
        "Sea A nuestro conjunto de caras (aplanadas y centradas restando la media). Entonces la matriz de covarianza $C$ se calcula de la siguiente manera: $C = AA^T$. Sin embargo, esta matriz es muy grande ($N^2xN^2$), y su cálculo puede ser muy costoso a nivel computacional. De modo que puede considerarse la matriz $L = A^TA$, que es mucho más pequeña ($MxM$), y cuyos $M$ vectores propios (y sus correspondientes valores propios) permiten el cálculo de los vectores propios de $C$ asociados con sus $M$ mayores valores propios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IC72zQXsI8r"
      },
      "outputs": [],
      "source": [
        "#Matriz de covarianza C=AA'\n",
        "#Calculamos L=A'A porque C es demasiado grande y costosa de calcular\n",
        "print('Calculando L = A\\'A...')\n",
        "A = S_processed.copy()\n",
        "L = np.matmul(A.T,A)\n",
        "print('Dimensiones de L: {}\\n'.format(L.shape))\n",
        "\n",
        "#Calculando los vectores propios y valores propios de L\n",
        "print('Calculando los vectores propios y valores propios de L...')\n",
        "dd, vv = np.linalg.eig(L)\n",
        "#vv son los vectores propios de L\n",
        "#dd son los valores propios de L y C\n",
        "print('Dimensiones del conjunto de vectores propios vv: {}'.format(vv.shape))\n",
        "print('||vv_0||= {} (ya está normalizado)\\n'.format(np.linalg.norm(vv[:,0])))\n",
        "#Eliminando los vectores propios con valor propio = 0\n",
        "print('Eliminando los vectores propios con valor propio = 0 (y sus vectores propios correspondientes)\\n')\n",
        "threshold = 1e-4\n",
        "n = sum(dd > threshold)\n",
        "d = np.zeros(n)\n",
        "v = np.zeros((vv.shape[0],n))\n",
        "j = 0\n",
        "for i in range(len(dd)):\n",
        "    if dd[i] > threshold:\n",
        "        d[j] = dd[i]\n",
        "        v[:,j] = vv[:,i]\n",
        "        j += 1\n",
        "    else:\n",
        "        print('Eliminando dd[{}] y vv[{}] (dd[{}]={})'.format(i,i,i,dd[i]))\n",
        "#Ordenando (ascendente)\n",
        "v = v[:,np.argsort(d)]\n",
        "d = np.sort(d)\n",
        "print('||v_0||= {} (ya está normalizado)\\n'.format(np.linalg.norm(v[:,0])))\n",
        "\n",
        "#Vectores propios de la matriz C\n",
        "print('Calculating the {} higher eigenvectors and eigenvalues of C = AA\\' (covariance matrix)...'.format(n))\n",
        "u = np.matmul(A,v)\n",
        "print('Dimensiones de u: {}'.format(u.shape))\n",
        "\n",
        "#Normalización de C\n",
        "print('||u_0||= {}\\n'.format(np.linalg.norm(u[:,0])))\n",
        "print('Normalizando los vectores propios de la matriz C...')\n",
        "u = normalize(u, axis = 0)\n",
        "print('||u_0||= {}'.format(np.linalg.norm(u[:,0])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtZjSLe5sI8u"
      },
      "source": [
        "Una vez tenemos los vectores propios u<sub>i</sub>, tranformándolos de nuevo en imágenes de NxN píxeles podemos obtener las _eigencaras_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RH062l2sI8v"
      },
      "outputs": [],
      "source": [
        "#Mostrar las eigen caras\n",
        "eigen_faces = np.ndarray((irow*icol,u.shape[1]))\n",
        "for i in range(u.shape[1]):\n",
        "    eigen_faces[:,i] = exposure.equalize_hist(u[:,i],nbins=256)\n",
        "eigen_faces = skimage.img_as_ubyte(eigen_faces)\n",
        "plot_images(eigen_faces[:,-16:],title = 'Eigen caras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EatpEfA2sI8x"
      },
      "source": [
        "# Reconstruyendo y clasificando nuevas caras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR0eI0xxsI8y"
      },
      "source": [
        "Una posible aplicación de las _eigencaras_ es reconstruir imágenes que no están dentro del conjunto de entrenamiento. En este caso se toman 16 imágenes de la base de datos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1SskDCGsI81"
      },
      "source": [
        "Dichas imágenes pueden reconstruirse como combinación linear de las _eigencaras_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEK_PAmYsI82"
      },
      "outputs": [],
      "source": [
        "T=16\n",
        "\n",
        "#Importar los nombres de las 16 primeras imágenes del conjunto de prueba\n",
        "dir_='test_set/'\n",
        "test_set_filenames = os.listdir(dir_)\n",
        "test_set_filenames.remove('.DS_Store')\n",
        "\n",
        "S_test_raw = np.ndarray((irow*icol,T))\n",
        "for i in range(T):\n",
        "    #Leer img\n",
        "    img = io.imread('test_set/{}'.format(test_set_filenames[i]))\n",
        "    #img = color.rgb2gray(img)\n",
        "    img = transform.resize(img, (irow,icol),anti_aliasing=True)\n",
        "    #Añadir img a la matriz\n",
        "    S_test_raw[:,i]= img.flatten()\n",
        "\n",
        "#Normalización\n",
        "S_test = S_test_raw.copy()\n",
        "for i in range(T):\n",
        "    S_test[:,i] = (S_test[:,i] - S_test[:,i].mean()) * ustd/S_test[:,i].std() + um\n",
        "\n",
        "#Centrado\n",
        "for i in range(T):\n",
        "    S_test[:,i] = S_test[:,i] - mean_img\n",
        "\n",
        "S_reshaped = np.ndarray((irow*icol,T))\n",
        "for i in range(T):\n",
        "    S_reshaped[:,i] = mean_img + np.dot(np.dot(u.T,S_test[:,i]),u.T)\n",
        "\n",
        "#Mostrar las img de entrada y las reconstruidas\n",
        "plot_images(S_test_raw,title = 'Imágenes de prueba')\n",
        "plot_images(S_reshaped,title = 'Imágenes reconstruidas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyUMWec1sI86"
      },
      "source": [
        "También puede calcularse distancia (disimilitud) entre las caras del conjunto de test y las del conjunto de entrenamiento:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp3Dj9m_sI86"
      },
      "outputs": [],
      "source": [
        "#Cálculo del peso de las eigencaras en la nueva imagen\n",
        "weights = np.zeros((u.shape[1],T))\n",
        "for i in range(T):\n",
        "    weights[:,i] = np.dot(u.T,S_test[:,i])\n",
        "\n",
        "omega = np.zeros((u.shape[1],A.shape[1]))\n",
        "for h in range(A.shape[1]):\n",
        "    omega[:,h] = np.dot(u.T, A[:,h].T)\n",
        "\n",
        "#Encontrar la distancia\n",
        "e = np.zeros((omega.shape[1],T))\n",
        "for i in range(T):\n",
        "    for j in range(omega.shape[1]):\n",
        "        diff_weight = weights[:,i] - omega[:,j]\n",
        "        e[j,i] = np.linalg.norm(diff_weight)\n",
        "\n",
        "ax, fig = plt.subplots(figsize=(8,6))\n",
        "plt.plot(e)\n",
        "plt.title('Distancia euclídea de las imágenes de prueba',fontsize = 14)\n",
        "plt.xlabel('Número de la imagen de entrenamiento')\n",
        "plt.ylabel('Distancia')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}